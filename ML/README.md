# ğŸ¤– Machine Learning - Proyectos Comparativos

Este mÃ³dulo contiene dos proyectos aplicados de Machine Learning enfocados en clasificaciÃ³n supervisada. Se comparan distintos algoritmos en contextos reales y acadÃ©micos, evaluando su rendimiento, interpretabilidad y aplicabilidad.

---

## ğŸ“Œ Proyecto 1: AnÃ¡lisis Comparativo de Algoritmos de ML  
### PredicciÃ³n de ContrataciÃ³n de Servicios

### ğŸ“ DescripciÃ³n del problema
Se busca predecir si un cliente contratarÃ¡ un servicio especÃ­fico, utilizando sus caracterÃ­sticas demogrÃ¡ficas y comportamentales.

### ğŸ’¼ Contexto empresarial
- **Objetivo**: Identificar clientes con alta probabilidad de contrataciÃ³n.
- **AplicaciÃ³n**: OptimizaciÃ³n de campaÃ±as de marketing y recursos comerciales.
- **Beneficio**: ReducciÃ³n de costos y aumento de conversiÃ³n.

### ğŸ“Š Dataset
- **Variable objetivo**: `Contratara_Servicio` (binaria: 0=No, 1=SÃ­).
- **Variables predictoras**: Datos del cliente (edad, historial, etc.).

### ğŸ§  Algoritmos evaluados
1. RegresiÃ³n LogÃ­stica  
2. K-Nearest Neighbors (KNN)  
3. Ãrbol de DecisiÃ³n  
4. Random Forest  
5. Support Vector Machine (SVM)

### âš™ï¸ MetodologÃ­a
- DivisiÃ³n: 70% entrenamiento / 30% prueba  
- NormalizaciÃ³n para modelos sensibles a escala  
- OptimizaciÃ³n de hiperparÃ¡metros  
- EvaluaciÃ³n con mÃºltiples mÃ©tricas (accuracy, matriz de confusiÃ³n, etc.)

### ğŸ“ˆ Resultados destacados
- **Random Forest**: Accuracy ~97â€“99%  
- **SVM (RBF)**: Accuracy ~96â€“98%  
- **Ãrbol de DecisiÃ³n**: Accuracy ~94â€“96%  
- **KNN**: Accuracy ~92â€“95%  
- **RegresiÃ³n LogÃ­stica**: Accuracy ~88â€“92%

### ğŸ” Insights clave
- Variables mÃ¡s influyentes: `[Top 3 del anÃ¡lisis]`  
- K Ã³ptimo para KNN: `{best_k}`  
- Kernel Ã³ptimo para SVM: `{best_kernel}`  
- Profundidad ideal para Ãrbol: 5

### ğŸ§­ Recomendaciones estratÃ©gicas
- **ProducciÃ³n**: Random Forest  
- **Explicabilidad**: Ãrbol de DecisiÃ³n  
- **Prototipado rÃ¡pido**: RegresiÃ³n LogÃ­stica  
- **SegmentaciÃ³n de clientes**: Basada en probabilidades de contrataciÃ³n

### âš ï¸ Limitaciones
- ValidaciÃ³n temporal pendiente  
- Costos de error deben ser considerados  
- Posible deriva del comportamiento del cliente

### ğŸš€ PrÃ³ximos pasos
1. ValidaciÃ³n cruzada  
2. TÃ©cnicas de ensemble avanzadas  
3. IngenierÃ­a de caracterÃ­sticas  
4. Pipeline de MLOps

### ğŸ“ Enlace al proyecto
[ğŸ”— Ver notebook del proyecto](./M4/s1/contratacion_servicios.ipynb)

---

## ğŸ“Œ Proyecto 2: ClasificaciÃ³n Supervisada - Dataset Iris

### ğŸ“ DescripciÃ³n del problema
Clasificar especies de flores iris (Setosa, Versicolor, Virginica) usando caracterÃ­sticas morfolÃ³gicas.

### ğŸŒ¸ CaracterÃ­sticas del dataset
- Longitud y ancho del sÃ©palo  
- Longitud y ancho del pÃ©talo  
- 150 muestras, 3 clases

### ğŸ§  Algoritmos comparados
1. RegresiÃ³n LogÃ­stica  
2. Ãrbol de DecisiÃ³n  
3. Random Forest  
4. Support Vector Machine (SVM)

### ğŸ“Š MÃ©tricas de evaluaciÃ³n
- Accuracy  
- Matriz de confusiÃ³n  
- Reporte de clasificaciÃ³n (Precision, Recall, F1-Score)

### ğŸ“ˆ Resultados
- Todos los modelos lograron **100% de accuracy** en el conjunto de prueba  
- Dataset ideal para clasificaciÃ³n por su limpieza y separaciÃ³n de clases

### ğŸ” Observaciones clave
- Random Forest y SVM son mÃ¡s robustos para producciÃ³n  
- RegresiÃ³n LogÃ­stica y Ãrbol de DecisiÃ³n son altamente interpretables  
- Dataset pequeÃ±o y limpio: ideal para demostraciÃ³n, no para generalizaciÃ³n

### ğŸ§­ Recomendaciones
- Para producciÃ³n: Random Forest o SVM  
- Para interpretabilidad: Ãrbol o RegresiÃ³n LogÃ­stica  
- Para datasets reales: aplicar validaciÃ³n cruzada

### ğŸ“ Enlace al proyecto
[ğŸ”— Ver notebook del proyecto](./M4/s2/iris_clasificacion.ipynb)

---

## ğŸ§  ConclusiÃ³n general

Estos proyectos demuestran cÃ³mo distintos algoritmos de clasificaciÃ³n pueden adaptarse a diferentes contextos. La elecciÃ³n del modelo depende del equilibrio entre precisiÃ³n, interpretabilidad y robustez. Se recomienda siempre evaluar mÃºltiples enfoques y validar con datos reales antes de implementar en producciÃ³n.
